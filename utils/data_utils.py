from scipy import signal
import torch
from torch.utils.data import Dataset
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib
import pandas as df

def plot_trace(
    trace_data,
    n_stations=8,
    save_path=None,
    save=False,
    title="",
    num=0,
    dpi=100,
    figsize=(10, 6),
    font_size=10,
):
    """
    Plots the multi-channel 1D seismograms and their corresponding expected outputs.

    Args:
        trace_data (np.ndarray): The input data array to be plotted.
        n_stations (int, optional): The number of stations in the data (rows). Separation between input/output is performed based on this value. Defaults to 8.
        save_path (str, optional): The file path where the figure should be saved. Defaults to None.
        save (bool, optional): Whether to save the figure to `save_path`. Defaults to False.
        title (str, optional): The title of the figure. Defaults to an empty string.
        num (int, optional): A numerical identifier for the figure. Defaults to 0.
        dpi (int, optional): The resolution of the figure in dots per inch. Defaults to 100.
        figsize (tuple, optional): The size of the figure as (width, height) in inches. Defaults to (10, 6).
        font_size (int, optional): The font size used in the figure. Defaults to 10.

    Returns:
        None

    """
    colors = {
        "input": "#4C72B0",
        0: "#808080",
        1: "#df8d5e",
        2: "#2ca02c",
        3: "#d62728",
        4: "#9467bd",
        5: "#8c564b",
    }
    labels = {
        1: "station 1",
        2: "station 2",
        3: "station 3",
        4: "station 4",
        5: "station 5",
        6: "station 6",
        7: "station 7",
        8: "station 8",
        9:  "BG",
        10: "VT",
        11: "LP",
        12: "TR",
        13: "AV",
        14: "IC",
    }
    matplotlib.rcParams.update({"font.size": font_size})

    fig, axes = plt.subplots(
        n_stations + 6, 1, sharex=True, figsize=figsize, num=num, dpi=dpi
    )  
    for idx, wave in enumerate(trace_data):
        if idx < n_stations:
            sns.lineplot(
                x=np.arange(trace_data.shape[1]) / 100,
                y=wave,
                ax=axes[idx],
                color=colors["input"],
                lw=0.8,
            )
            axes[idx].set_ylim(-1.2, 1.2)  
        else:
            sns.lineplot(
                x=np.arange(trace_data.shape[1]) / 100,
                y=wave,
                ax=axes[idx],
                color=colors[idx - n_stations],
                lw=2,
            )
            axes[idx].set_ylim(-.1, 1.1) 
        axes[idx].set_ylabel(f"                {labels[idx + 1]}", rotation=0)
        axes[idx].yaxis.set_label_position("right")  # Place y-labels on the right
    axes[-1].set_xlabel("time [s]")  
    if save:
        plt.savefig(save_path)
        plt.close("all")
    else:
        plt.suptitle(title)


def fold_X(X, N=256):
    """
    Performs the Folding procedure over a multi-channel 1D tensor to obtain a 'NxN' image.

    Args:
        X (torch.Tensor): The input multi-channel 1D tensor to be folded.
        N (int, optional): The size of the image to be generated. Defaults to 256.

    Returns:
        torch.Tensor: The reshaped tensor of size (1, N, N).
    """    
    patches = X.unfold(1, N, N)
    patches = patches.permute(1, 0, 2)
    X = patches.reshape(-1, N).unsqueeze(0)
    return X.float()


def fold_y(y, N=256, n_classes=6, n_stations=8):
    """
    Folds the target tensor `y`, generating `n_classes` 2D masks of size `N x N`.

    Args:
        y (torch.Tensor): The target tensor to be folded.
        N (int, optional): The size of the masks to be generated. Defaults to 256.
        n_classes (int, optional): The number of classes in the dataset. Defaults to 6.
        n_stations (int, optional): The number of stations in the data. Defaults to 8.

    Returns:
        torch.Tensor: The obtained class-specific 2D masks (n_classes, N, N), converted to float.
    """    
    patches = y.repeat(n_stations, 1, 1)
    patches = patches.permute(1, 0, 2)
    patches = patches.unfold(2, N, N)
    patches = patches.permute(0, 2, 1, 3)
    y = patches.reshape(n_classes, -1, N)
    return y.float()


def unfold_y(mask, W=8192, N=256, n_classes=6):
    """
    Unfolds the 2D predicted masks `mask` (produced by the model) back into the multi-channel 1D array `y`, which represents time segmentation.

    Args:
        mask (torch.Tensor): The `n_classes x N x N` output masks generated by the model.
        W (int, optional): The original length of the unfolded data. Defaults to 8192.
        N (int, optional): The size of the masks. Defaults to 256.
        n_classes (int, optional): The number of classes in the data. Defaults to 6.

    Returns:
        torch.Tensor: The model prediction along time (batch_size, n_classes, 1,  W).
    """    
    output = torch.zeros([len(mask), n_classes, W])
    for idx, patches in enumerate(mask):
        patches = patches.unfold(1, 8, 8)
        patches = patches.permute(0, 3, 1, 2).reshape(n_classes, 8, N * N // 8)
        patches_y = patches.sum(axis=1)
        patches_y = patches_y / patches_y.max()
        output[idx] = patches_y
    del patches_y, mask
    return output.float()

def detected_events(BG_diff):
    """
    Detect events based on changes in the BG array difference values.

    Args:
        BG_diff (np.ndarray): An array representing the difference in the BG array. 
                              Values of -1 indicate the start of an event, and values of 1 indicate the end.

    Returns:
        pd.DataFrame: A DataFrame containing detected events with the following columns:
            - "start": The starting index of the event.
            - "end": The ending index of the event.
            - "length": The duration of the event in samples.

    Notes:
        If no start or end indices are found, defaults are used: starting at index 0 and ending at the last index.
    """    
    start_indices = np.where(BG_diff == -1)[0]
    if len(start_indices) == 0:
        start_indices = np.array([0])
    end_indices = np.where(BG_diff == 1)[0]
    if len(end_indices) == 0:
        end_indices = np.array([-1])
    events = []
    last_end_idx = -1
    for start in start_indices:
        valid_ends = end_indices[end_indices > start]
        if valid_ends.size > 0:
            end = valid_ends[0]
            events.append((start, end, end - start))
            last_end_idx = end
        else:
            events.append([start, len(BG_diff) - 1, len(BG_diff) - 1 - start])
    if last_end_idx != -1:
        invalid_ends = end_indices[end_indices < start_indices[0]]
        for invalid_end in invalid_ends:
            events.insert(0, (0, invalid_end, invalid_end))
    events_df = df.DataFrame(events, columns=["start", "end", "length"])
    return events_df


def post_processing(
    output,
    classes={
        0.0: "BG",
        1.0: "VT",
        2.0: "LP",
        3.0: "TR",
        4.0: "AV",
        5.0: "IC",
    },
):
    """
    Process the -unfolded- multi-channel 1D output of the segmentation model to extract event information.

    Args:
        output (np.ndarray): The model's output probabilities for each class across time frames.
        classes (dict): A mapping of class indices to class labels.

    Returns:
        pd.DataFrame: A DataFrame containing event details with the following columns:
            - "start": The starting index of the event.
            - "end": The ending index of the event.
            - "length": The duration of the event in samples.
            - "class_n": The predicted class number for the event.
            - "class_label": The predicted class label for the event.

    Notes:
        If no events are detected, a default row with the entire signal length is returned.
    """    
    max_indices = np.argmax(output, axis=0)
    processed_out = np.eye(len(output))[max_indices].T
    BG_diff = np.diff(processed_out[0])
    if np.abs(BG_diff).sum() != 0:
        events_df = detected_events(BG_diff)
        events_df["class_n"] = None
        events_df["class_label"] = None
        for index, row in events_df.iterrows():
            start_ = row["start"]
            end_ = row["end"]
            length = row["length"]
            predicted_class = processed_out[1:, start_:end_].sum(axis=1).argmax() + 1
            pred_label = classes[predicted_class]
            events_df.at[index, "class_n"] = predicted_class
            events_df.at[index, "class_label"] = pred_label
    else:
        events_df = df.DataFrame(
            [[0, 8191, 8192, None, None]],
            columns=["start", "end", "length", "class_n", "class_label"],
        )
        predicted_class = processed_out.sum(axis=1).argmax()
        pred_label = classes[predicted_class]
        events_df.at[0, "class_n"] = predicted_class
        events_df.at[0, "class_label"] = pred_label
    return events_df



def plot_segmentation(
    input_traces,
    detected_events_df,
    n_stations=8,
    save_path=None,
    save=False,
    title="",
    num=0,
    dpi=100,
    figsize=(10, 6),
):
    colors = {
        "input": "#4C72B0",
        0: "#808080",
        1: "#df8d5e",
        2: "#2ca02c",
        3: "#d62728",
        4: "#9467bd",
        5: "#8c564b",
    }
    labels = {
        1: "FRE",
        2: "SHG",
        3: "NBL",
        4: "CHA",
        5: "FU2",
        6: "CHS",
        7: "LBN",
        8: "PLA",
        9: "BG",
        10: "VT",
        11: "LP",
        12: "TR",
        13: "AV",
        14: "IC",
    }

    """
    Plots the input traces along with detected events highlighted.

    Args:
        input_traces (np.ndarray): An array of shape (n_stations, length) representing the input signal traces.
        detected_events_df (pd.DataFrame): DataFrame containing detected event information.
        n_stations (int, optional): Number of stations. Defaults to 8.
        save_path (str, optional): Path to save the figure if `save` is True.
        save (bool, optional): Whether to save the figure or display it. Default is False.
        title (str, optional): Title for the plot.
        num (int, optional): Figure number for the plot.
        dpi (int, optional): Dots per inch for the saved figure.
        figsize (tuple, optional): Size of the figure.

    Returns:
        None

    Notes:
        The function highlights detected events with colored spans and annotates them with class labels.
    """
    fig, axes = plt.subplots(
        n_stations, 1, sharex=True, figsize=figsize, num=num, dpi=dpi
    )  # Increased height to 12 for better spacing
    for idx, wave in enumerate(input_traces):
        if idx <= 7:
            sns.lineplot(
                x=np.arange(input_traces.shape[1]) / 100,
                y=wave,
                ax=axes[idx],
                color=colors["input"],
                lw=1,
            )
        # Set custom y-label
        axes[idx].set_ylabel(f"           {labels[idx + 1]}", rotation=0)
        # axes[idx].set_yticks([])  # Remove y-axis ticks

        axes[-1].set_xlabel("time [s]")  # Shared x-axis label
        axes[idx].yaxis.set_label_position("right")  # Place y-labels on the left
        axes[idx].set_ylim(-1.2, 1.2)  # Set limits for y-axis
    #detected_events_df = detected_events_df.query("length>250")
    for index, row in detected_events_df.iterrows():
        for idx, wave in enumerate(input_traces):
            axes[idx].axvspan(
                row["start"] / 100,
                row["end"] / 100,
                color=colors[row["class_n"]],
                alpha=0.3,
            )
        midpoint = (row["start"] + row["end"]) / 200  # Midpoint of the event
        plt.text(
            midpoint,
            1.05,
            row["class_label"],
            ha="center",
            va="bottom",
            transform=axes[0].get_xaxis_transform(),
            fontsize=12,
        )

    if save:
        plt.savefig(save_path)
        plt.close("all" )
    else:
        plt.suptitle(title)
        # plt.show()