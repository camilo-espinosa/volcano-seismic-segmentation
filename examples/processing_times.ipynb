{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f376551e",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc12fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor, cuda\n",
    "import pandas as pd\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008e165c",
   "metadata": {},
   "source": [
    "### Add utils to sys to import our custom scripts\n",
    "**Note:** This notebook should be run from the `examples` folder to ensure the correct imports and file paths are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aabc0db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Camilo\\Volcanes_UFRO\\PAPER IEEE\\repo\\.repo_venv\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Go up one level from 'examples' and point to 'utils' folder\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'utils'))\n",
    "# Add the 'utils' folder to sys.path\n",
    "sys.path.append(utils_path)\n",
    "models_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'models'))\n",
    "# Add the 'models' folder to sys.path\n",
    "sys.path.append(models_path)\n",
    "import data_utils\n",
    "import model_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d791f0",
   "metadata": {},
   "source": [
    "### Load the model\n",
    "\n",
    "Model can be loaded through the model_selector() function. Available architectures are: \"UNet\", \"UNetPlusPlus\", \"DeepLabV3\", \"SwinUNet\", and PhaseNet. If you wish to load the weights generated by the article, you can set the pretrained argument to True, it automatically downloads the weights from [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15098817.svg)](https://doi.org/10.5281/zenodo.15098817) (weights are only available for input size N=256). Number of parameters for each model at each input size evaluated in the article is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cf04b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if cuda.is_available() == True else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de50a9f",
   "metadata": {},
   "source": [
    "### Load continuous trace\n",
    "\n",
    "Data can be downloaded from [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.17163020.svg)](https://doi.org/10.5281/zenodo.17163020):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6170665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi = \"10.5281/zenodo.17163020\"\n",
    "record_id = doi.split(\".\")[-1]\n",
    "metadata_url = f\"https://zenodo.org/api/records/{record_id}\"\n",
    "response = requests.get(metadata_url)\n",
    "metadata = response.json()\n",
    "files = metadata[\"files\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9d00a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVCh_10h_continuous_trace.zip\n",
      "Downloaded NVCh_10h_continuous_trace.zip\n",
      "Extracting files...\n",
      "Files extracted\n"
     ]
    }
   ],
   "source": [
    "file_to_download = files[4]  # 0: NVCh_10h_continuous_trace.zip - https://zenodo.org/api/records/17163020/files/NVCh_10h_continuous_trace.zip/content\n",
    "print(file_to_download[\"key\"] )\n",
    "file_url = file_to_download[\"links\"][\"self\"]\n",
    "filename = file_to_download[\"key\"] \n",
    "response = requests.get(file_url, stream=True)\n",
    "\n",
    "with open(filename, \"wb\") as f:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        f.write(chunk)\n",
    "print(f\"Downloaded {filename}\")\n",
    "\n",
    "print(f\"Extracting files...\")\n",
    "\n",
    "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.getcwd())  # or use a specific path\n",
    "print(f\"Files extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f2a4b",
   "metadata": {},
   "source": [
    "After downloading we load the full seismic trace and the reference dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"NVCh_10h_continuous_trace.npy\"\n",
    "continuous_trace = np.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c5367",
   "metadata": {},
   "source": [
    "Timing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128773f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 1\n",
    "window_size = 8192\n",
    "stride = 2000\n",
    "total_time_list = []\n",
    "for arch in [\"UNet\", \"UNetPlusPlus\", \"SwinUNet\", \"DeepLabV3\"]:\n",
    "    model = model_utils.model_selector(arch=arch, N=256, pretrained=True).to(device)\n",
    "    for stride in [7000,6000,5000,4000,3000,2000,1000,500,250]:\n",
    "        activation_buffer = np.zeros([6, continuous_trace.shape[1]])\n",
    "        n_windows = ((continuous_trace.shape[1] - window_size) // stride) + 1\n",
    "        print_interval = int(n_windows / 5)\n",
    "\n",
    "        _ = model.eval()\n",
    "        window_index = 0\n",
    "\n",
    "        # start timing\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch in data_utils.generate_overlapping_batches(\n",
    "            continuous_trace, window_size=window_size, stride=stride, batch_size=batch_size\n",
    "        ):\n",
    "            X = data_utils.patch_stacking_X(tensor(batch[:, 1:9, :])).to(device)\n",
    "            output = model(X)\n",
    "            output = data_utils.activation_unstacking(output, window_size, 256, 6)\n",
    "            for idx in range(len(output)):\n",
    "                offset = window_index * stride            \n",
    "                probabilities = output[idx].detach().cpu().numpy()\n",
    "                activation_buffer[:, offset:offset+window_size] += probabilities\n",
    "                window_index += 1\n",
    "                # if window_index % print_interval == 0:\n",
    "                #     print(\"windows processed:\", window_index, \"/\", n_windows)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        total_time = end_time - start_time\n",
    "        avg_time_per_window = total_time / window_index\n",
    "\n",
    "        total_time_list.append({\"stride\":stride,\n",
    "                                \"arch\":arch,\n",
    "                                \"total_time\":total_time,\n",
    "                                \"avg_time_per_window\":avg_time_per_window})\n",
    "        print(f\"{arch} - Total time: {total_time:.2f} seconds\")\n",
    "        print(f\"{arch} - Average time per window: {avg_time_per_window:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5081a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time_df = pd.DataFrame(total_time_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa65471b",
   "metadata": {},
   "source": [
    "Time [ms] to process a single window (average accross strides 2,5 to 70 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b726f3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             avg_time_per_window             \n",
      "                             max   mean   min\n",
      "arch                                         \n",
      "DeepLabV3                   20.0  14.33  13.0\n",
      "SwinUNet                    29.0  23.33  22.0\n",
      "UNet                        10.0   7.22   6.0\n",
      "UNetPlusPlus                15.0  11.89  11.0\n"
     ]
    }
   ],
   "source": [
    "agg_df = total_time_df.groupby(\"arch\").agg({\n",
    "    \"avg_time_per_window\": [\"max\", \"mean\", \"min\"]\n",
    "})\n",
    "agg_df = agg_df*1000#.round(3)\n",
    "agg_df = agg_df.round(2)\n",
    "\n",
    "print(agg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3507fd",
   "metadata": {},
   "source": [
    "Total time [s] to process the entire 10-hour continuous trace (average accross strides 2,5 to 70 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe42e82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             total_time              \n",
      "                    max   mean    min\n",
      "arch                                 \n",
      "DeepLabV3        212.73  49.49   9.40\n",
      "SwinUNet         339.02  80.56  15.02\n",
      "UNet             101.87  24.29   4.06\n",
      "UNetPlusPlus     164.10  39.96   7.01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agg_df = total_time_df.groupby(\"arch\").agg({\n",
    "    \"total_time\": [\"max\", \"mean\", \"min\"],\n",
    "})\n",
    "agg_df= agg_df.round(2)\n",
    "\n",
    "print(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63147ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".repo_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
