{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b37a90",
   "metadata": {},
   "source": [
    "# Demonstration of Continuous data event recognition using Semantic Segmentation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d10b6",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor, cuda\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a759a",
   "metadata": {},
   "source": [
    "### Add utils to sys to import our custom scripts\n",
    "**Note:** This notebook should be run from the `examples` folder to ensure the correct imports and file paths are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bcbde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go up one level from 'examples' and point to 'utils' folder\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'utils'))\n",
    "# Add the 'utils' folder to sys.path\n",
    "sys.path.append(utils_path)\n",
    "models_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'models'))\n",
    "# Add the 'models' folder to sys.path\n",
    "sys.path.append(models_path)\n",
    "import data_utils\n",
    "import model_utils\n",
    "import real_time_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f4f5ae",
   "metadata": {},
   "source": [
    "### Load the model\n",
    "\n",
    "Model can be loaded through the model_selector() function. Available architectures are: \"UNet\", \"UNetPlusPlus\", \"DeepLabV3\", \"SwinUNet\", and PhaseNet. If you wish to load the weights generated by the article, you can set the pretrained argument to True, it automatically downloads the weights from [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15098817.svg)](https://doi.org/10.5281/zenodo.15098817) (weights are only available for input size N=256). Number of parameters for each model at each input size evaluated in the article is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404518fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if cuda.is_available() == True else \"cpu\"\n",
    "model = model_utils.model_selector(arch='UNetPlusPlus', N=256, pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2479e27",
   "metadata": {},
   "source": [
    "### Load continuous trace\n",
    "\n",
    "Data can be downloaded from [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15384923.svg)](https://doi.org/10.5281/zenodo.15384923):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi = \"10.5281/zenodo.15384923\"\n",
    "record_id = doi.split(\".\")[-1]\n",
    "metadata_url = f\"https://zenodo.org/api/records/{record_id}\"\n",
    "response = requests.get(metadata_url)\n",
    "metadata = response.json()\n",
    "files = metadata[\"files\"]\n",
    "file_to_download = files[2]  # 0: NVCh_10h_continuous_trace.zip - https://zenodo.org/api/records/15384923/files/NVCh_10h_continuous_trace.zip/content\n",
    "file_url = file_to_download[\"links\"][\"download\"]\n",
    "filename = file_to_download[\"key\"] \n",
    "response = requests.get(file_url, stream=True)\n",
    "\n",
    "with open(filename, \"wb\") as f:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        f.write(chunk)\n",
    "print(f\"Downloaded {filename}\")\n",
    "\n",
    "print(f\"Extracting files...\")\n",
    "\n",
    "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.getcwd())  # or use a specific path\n",
    "print(f\"Files extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c47cf",
   "metadata": {},
   "source": [
    "After downloading we load the full seismic trace and the reference dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bec412",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_trace = np.load(filename)\n",
    "reference = pd.read_csv(\"big_trace_reference_v1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eadd0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference.value_counts(\"event_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1541009",
   "metadata": {},
   "source": [
    "## Sliding window:\n",
    "\n",
    "We apply our model in a sliding window setup. Stride can be manually selected and is by default set to the lighter value of 7000 (70 seconds). Batch size can also be selected and is by default 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d682e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "window_size = 8192\n",
    "stride = 7000\n",
    "\n",
    "n_windows = ((continuous_trace.shape[1] - window_size) // stride) + 1\n",
    "activations = np.zeros([6,continuous_trace.shape[1]])\n",
    "work_path = f\"D:/Camilo/Volcanes_UFRO/RESULTADOS/general_performance/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c77bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_utils.SuppressPrint():\n",
    "    model.eval()\n",
    "window_index = 0\n",
    "for batch in real_time_utils.generate_overlapping_batches(\n",
    "    continuous_trace, window_size=window_size, stride=stride, batch_size=batch_size,noise_norm=noise_norm\n",
    "):\n",
    "    if window_index % 50 == 0:\n",
    "        print(window_index, \"/\", n_windows)\n",
    "    X = data_utils.patch_stacking_X(tensor(batch[:, 1:9, :])).to(device)\n",
    "    output = model(X)\n",
    "    output = data_utils.activation_unstacking(output, window_size, N=256, n_classes=6)\n",
    "    for idx in range(len(output)):\n",
    "        offset = window_index * stride            \n",
    "        probabilities = output[idx].detach().cpu().numpy()\n",
    "        activations[:,offset:offset+window_size]=activations[:,offset:offset+window_size]+probabilities\n",
    "        window_index += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".repo_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
